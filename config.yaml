# configuration file for bot and twitter data extraction

# bot configuration (training done with chatgpt)
chatbot:
  # underscore necessary for code to work
  character: donald_trump
  # run mode supported are: 
  # *light: doesn't use a fine tuned model and can be combined with mimic_response below
  # *normal: use a fine tuned model (openai::model_name))
  run_mode: normal
  # supported option are:
  # *exact: return exact historical match 
  # *mimic_response: return response that mimics the historical match
  search_mode: exact
  similarity_threshold: 0.9

# openai configuration
openai: 
  openai_key: <OPENAI_KEY> 
  # engine for synthetic tweets generation
  openai_engine: text-davinci-003
  # engine to use for fine-tuning 
  openai_train_engine: davinci
  # change fine tune job id when running own models
  fine_tune_job_id: ft-DPzMF6vRZ7yS0ToqJYpWEW5f
  # change model name when running own models
  model_name: davinci:ft-jair-ltd-2023-06-14-17-47-18

# twitter configuration
# if twitter_api_key is None, the bot will use a mock random tweets generator
twitter:
  twitter_handle: realDonaldTrump
  num_tweets: 400
  consumer_key: <CONSUMER_KEY> 
  consumer_secret: <CONSUMER_SECRET>
  access_token: <ACCESS_TOKEN>
  access_token_secret: <ACCESS_TOKEN_SECRET>
  twitter_api_key: <TWITTER_API_KEY>
  twitter_handle: realDonaldTrump

# cloud memory configuration
# https://app.activeloop.ai/login
deeplake:
  account_name: <ACCOUNT_NAME>
  api_key: <API_KEY>
  local_path: data_db
  # setting nk too high lead to memory issues
  search_nk: 10
